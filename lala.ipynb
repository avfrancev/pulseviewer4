{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Union\n",
    "\n",
    "from IPython import get_ipython\n",
    "from IPython.display import Image\n",
    "\n",
    "import autogen\n",
    "\n",
    "config_list = [\n",
    "    {\n",
    "        # 'model': 'gpt-4',\n",
    "        'api_type': 'open_ai',\n",
    "        'api_base': 'http://localhost:1234/v1',\n",
    "        'api_key': 'null',\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "I need to create a YouTube Script that talks about the latest paper about gpt-4 on arxiv and its potential applications in software.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Completions.create() got an unexpected keyword argument 'api_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/admin/PROJECTS/tests_vite/lala.ipynb Cell 2\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/admin/PROJECTS/tests_vite/lala.ipynb#W1sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m groupchat \u001b[39m=\u001b[39m GroupChat(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/admin/PROJECTS/tests_vite/lala.ipynb#W1sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     agents\u001b[39m=\u001b[39m[user_proxy, content_creator, script_writer, researcher, reviewer], messages\u001b[39m=\u001b[39m[]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/admin/PROJECTS/tests_vite/lala.ipynb#W1sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/admin/PROJECTS/tests_vite/lala.ipynb#W1sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m manager \u001b[39m=\u001b[39m GroupChatManager(groupchat\u001b[39m=\u001b[39mgroupchat, llm_config\u001b[39m=\u001b[39mllm_config)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/admin/PROJECTS/tests_vite/lala.ipynb#W1sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m user_proxy\u001b[39m.\u001b[39;49minitiate_chat(manager, message\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mI need to create a YouTube Script that talks about the latest paper about gpt-4 on arxiv and its potential applications in software.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:550\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[0;34m(self, recipient, clear_history, silent, **context)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Initiate a chat with the recipient agent.\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \n\u001b[1;32m    538\u001b[0m \u001b[39mReset the consecutive auto reply counter.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[39m        \"message\" needs to be provided if the `generate_init_message` method is not overridden.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_chat(recipient, clear_history)\n\u001b[0;32m--> 550\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_init_message(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcontext), recipient, silent\u001b[39m=\u001b[39;49msilent)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:348\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    346\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[0;32m--> 348\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[1;32m    349\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    351\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    352\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:481\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[39mif\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreply_at_receive[sender] \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 481\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_reply(messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchat_messages[sender], sender\u001b[39m=\u001b[39;49msender)\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(reply, sender, silent\u001b[39m=\u001b[39msilent)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:906\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[1;32m    904\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    905\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[39m\"\u001b[39m\u001b[39mtrigger\u001b[39m\u001b[39m\"\u001b[39m], sender):\n\u001b[0;32m--> 906\u001b[0m     final, reply \u001b[39m=\u001b[39m reply_func(\u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, sender\u001b[39m=\u001b[39;49msender, config\u001b[39m=\u001b[39;49mreply_func_tuple[\u001b[39m\"\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    907\u001b[0m     \u001b[39mif\u001b[39;00m final:\n\u001b[1;32m    908\u001b[0m         \u001b[39mreturn\u001b[39;00m reply\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/groupchat.py:269\u001b[0m, in \u001b[0;36mGroupChatManager.run_chat\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m     \u001b[39m# select the next speaker\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m     speaker \u001b[39m=\u001b[39m groupchat\u001b[39m.\u001b[39;49mselect_speaker(speaker, \u001b[39mself\u001b[39;49m)\n\u001b[1;32m    270\u001b[0m     \u001b[39m# let the speaker speak\u001b[39;00m\n\u001b[1;32m    271\u001b[0m     reply \u001b[39m=\u001b[39m speaker\u001b[39m.\u001b[39mgenerate_reply(sender\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/groupchat.py:158\u001b[0m, in \u001b[0;36mGroupChat.select_speaker\u001b[0;34m(self, last_speaker, selector)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39m# auto speaker selection\u001b[39;00m\n\u001b[1;32m    157\u001b[0m selector\u001b[39m.\u001b[39mupdate_system_message(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mselect_speaker_msg(agents))\n\u001b[0;32m--> 158\u001b[0m final, name \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mgenerate_oai_reply(\n\u001b[1;32m    159\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmessages\n\u001b[1;32m    160\u001b[0m     \u001b[39m+\u001b[39;49m [\n\u001b[1;32m    161\u001b[0m         {\n\u001b[1;32m    162\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    163\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mRead the above conversation. Then select the next role from \u001b[39;49m\u001b[39m{\u001b[39;49;00m[agent\u001b[39m.\u001b[39;49mname\u001b[39m \u001b[39;49m\u001b[39mfor\u001b[39;49;00m\u001b[39m \u001b[39;49magent\u001b[39m \u001b[39;49m\u001b[39min\u001b[39;49;00m\u001b[39m \u001b[39;49magents]\u001b[39m}\u001b[39;49;00m\u001b[39m to play. Only return the role.\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    164\u001b[0m         }\n\u001b[1;32m    165\u001b[0m     ]\n\u001b[1;32m    166\u001b[0m )\n\u001b[1;32m    167\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m final:\n\u001b[1;32m    168\u001b[0m     \u001b[39m# the LLM client is None, thus no reply is generated. Use round robin instead.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnext_agent(last_speaker, agents)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:625\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m    622\u001b[0m     messages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_oai_messages[sender]\n\u001b[1;32m    624\u001b[0m \u001b[39m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[0;32m--> 625\u001b[0m response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m    626\u001b[0m     context\u001b[39m=\u001b[39;49mmessages[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mcontext\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m), messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_oai_system_message \u001b[39m+\u001b[39;49m messages\n\u001b[1;32m    627\u001b[0m )\n\u001b[1;32m    628\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m, client\u001b[39m.\u001b[39mextract_text_or_function_call(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/oai/client.py:247\u001b[0m, in \u001b[0;36mOpenAIWrapper.create\u001b[0;34m(self, **config)\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[39mcontinue\u001b[39;00m  \u001b[39m# filter is not passed; try the next config\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 247\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_completions_create(client, params)\n\u001b[1;32m    248\u001b[0m \u001b[39mexcept\u001b[39;00m APIError:\n\u001b[1;32m    249\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconfig \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m failed\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/oai/client.py:327\u001b[0m, in \u001b[0;36mOpenAIWrapper._completions_create\u001b[0;34m(self, client, params)\u001b[0m\n\u001b[1;32m    325\u001b[0m     params \u001b[39m=\u001b[39m params\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    326\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 327\u001b[0m     response \u001b[39m=\u001b[39m completions\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    328\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/openai/_utils/_utils.py:271\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    270\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 271\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: Completions.create() got an unexpected keyword argument 'api_type'"
     ]
    }
   ],
   "source": [
    "from autogen import AssistantAgent, UserProxyAgent, GroupChat, GroupChatManager\n",
    "\n",
    "config_list = [\n",
    "    {\n",
    "        # \"api_type\": \"open_ai\",\n",
    "        \"api_base\": \"http://localhost:1234/v1\",\n",
    "        \"api_key\": \"NULL\"\n",
    "    }\n",
    "]\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"seed\": 47,\n",
    "    \"temperature\": 0.5,\n",
    "    \"max_tokens\": -1,\n",
    "    \"timeout\": 6000\n",
    "}\n",
    "\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    system_message=\"A human admin.\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "content_creator = AssistantAgent(\n",
    "    name=\"content_creator\",\n",
    "    system_message=\"I am a content creator that talks about exciting technologies about AI.  I want to create exciting content for my audience that is about the latest AI technology.  I want to provide in-depth details of the latest AI white papers.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "script_writer = AssistantAgent(\n",
    "    name=\"Script_Writer\",\n",
    "    system_message=\"I am a script writer for the Content Creator.  This should be an eloquently written script so the Content Creator can talk to the audience about AI.\",\n",
    "    llm_config=llm_config\n",
    ")\n",
    "\n",
    "researcher = AssistantAgent(\n",
    "    name=\"Researcher\",\n",
    "    system_message=\"I am the researcher for the Content Creator and look up the latest white papers in AI.  Make sure to include the white paper Title and Year it was introduced to the Script_Writer.\",\n",
    "    llm_config=llm_config\n",
    ")\n",
    "\n",
    "reviewer = AssistantAgent(\n",
    "    name=\"Reviewer\",\n",
    "    system_message=\"I am the reviewer for the Content Creator, Script Writer, and Researcher once they are done and have come up with a script.  I will double check the script and provide feedback.\",\n",
    "    llm_config=llm_config\n",
    ")\n",
    "\n",
    "groupchat = GroupChat(\n",
    "    agents=[user_proxy, content_creator, script_writer, researcher, reviewer], messages=[]\n",
    ")\n",
    "manager = GroupChatManager(groupchat=groupchat, llm_config=llm_config)\n",
    "\n",
    "user_proxy.initiate_chat(manager, message=\"I need to create a YouTube Script that talks about the latest paper about gpt-4 on arxiv and its potential applications in software.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
